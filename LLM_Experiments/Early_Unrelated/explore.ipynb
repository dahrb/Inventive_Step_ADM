{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987c8c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from openai import OpenAI  # Standard synchronous client\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093c8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Replace with your actual server URL from the SLURM log (e.g., http://gpu12:8000/v1)\n",
    "API_BASE = \"http://gpu33.barkla2.liv.alces.network:8000/v1\"\n",
    "API_KEY = \"EMPTY\"\n",
    "\n",
    "# Initialize Synchronous Client\n",
    "client = OpenAI(base_url=API_BASE, api_key=API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda54b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_weather_tool(location, unit=\"celsius\"):\n",
    "    \"\"\"\n",
    "    Simulates checking a weather API.\n",
    "    \"\"\"\n",
    "    # Database of fake weather conditions\n",
    "    weather_db = {\n",
    "        \"liverpool\": \"Rainy, 12 degrees, Wind: High\",\n",
    "        \"san francisco\": \"Foggy, 16 degrees, Wind: Moderate\",\n",
    "        \"london\": \"Cloudy, 15 degrees, Wind: Low\",\n",
    "        \"marengo\": \"Sunny, 25 degrees, Wind: None\",\n",
    "    }\n",
    "    \n",
    "    # Simple lookup logic\n",
    "    key = location.lower()\n",
    "    for city, weather in weather_db.items():\n",
    "        if city in key:\n",
    "            return json.dumps({\"location\": location, \"weather\": weather, \"unit\": unit})\n",
    "            \n",
    "    return json.dumps({\"error\": f\"Location '{location}' not found.\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc20560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "        \"tool\": \"cyan\",\n",
    "    }\n",
    "\n",
    "    for message in messages:\n",
    "        # Use getattr for objects, .get for dicts\n",
    "        if isinstance(message, dict):\n",
    "            role = message.get(\"role\", None)\n",
    "            content = message.get(\"content\", None)\n",
    "            function_call = message.get(\"function_call\", None)\n",
    "            name = message.get(\"name\", None)\n",
    "        else:\n",
    "            role = getattr(message, \"role\", None)\n",
    "            content = getattr(message, \"content\", None)\n",
    "            function_call = getattr(message, \"function_call\", None)\n",
    "            name = getattr(message, \"name\", None)\n",
    "\n",
    "        color = role_to_color.get(role, \"white\")\n",
    "        if role == \"system\":\n",
    "            print(colored(f\"system: {content}\\n\", color))\n",
    "        elif role == \"user\":\n",
    "            print(colored(f\"user: {content}\\n\", color))\n",
    "        elif role == \"assistant\" and function_call:\n",
    "            print(colored(f\"assistant: {function_call}\\n\", color))\n",
    "        elif role == \"assistant\":\n",
    "            print(colored(f\"assistant: {content}\\n\", color))\n",
    "        elif role == \"function\":\n",
    "            print(colored(f\"function ({name}): {content}\\n\", color))\n",
    "        elif role == \"tool\":\n",
    "            print(colored(f\"tool ({name}): {content}\\n\", color))\n",
    "        else:\n",
    "            print(colored(f\"{role}: {content}\\n\", color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf94328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tool\n",
    "\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\"type\": \"string\", \"description\":\"location of the place we need the weather for \"},\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c594b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=\"gpt-oss-120b\"):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            temperature=0.0,\n",
    "            reasoning_effort='high',\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a333534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='chatcmpl-tool-f237dd05d420497a864a56f27d7a79e1', function=Function(arguments='{\"location\": \"Liverpool\"}', name='get_weather'), type='function')], reasoning='The user asks: \"What is the weather like in Liverpool?\" This is a location-based weather request. We need to get the current weather for Liverpool. Use the get_weather function. The function expects location string and optional unit. We can request default unit (maybe Celsius). The user didn\\'t specify unit, so we can use default. Let\\'s call get_weather with location \"Liverpool\".', reasoning_content='The user asks: \"What is the weather like in Liverpool?\" This is a location-based weather request. We need to get the current weather for Liverpool. Use the get_weather function. The function expects location string and optional unit. We can request default unit (maybe Celsius). The user didn\\'t specify unit, so we can use default. Let\\'s call get_weather with location \"Liverpool\".')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"You are a weather helper. If any question doesn't concern a location for which the user wishes to know the weather then respond that the request is invalid. Call tools to answer the weather.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"What is the weather like in Liverpool?\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_weather\"}})\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26165007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Liverpool'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'unit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(tool_query_string)\n\u001b[32m     13\u001b[39m location = tool_query_string[\u001b[33m\"\u001b[39m\u001b[33mlocation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m unit = \u001b[43mtool_query_string\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     16\u001b[39m tool_result = execute_weather_tool(location=location,unit=unit)\n\u001b[32m     18\u001b[39m messages.append({\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mtool\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtool_call_id\u001b[39m\u001b[33m\"\u001b[39m:tool_call_id, \n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: tool_function_name, \n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:tool_result\n\u001b[32m     23\u001b[39m })\n",
      "\u001b[31mKeyError\u001b[39m: 'unit'"
     ]
    }
   ],
   "source": [
    "# Step 2: determine if the response from the model includes a tool call.   \n",
    "tool_calls = assistant_message.tool_calls\n",
    "\n",
    "if tool_calls:\n",
    "    # If true the model will return the name of the tool / function to call and the argument(s)  \n",
    "    tool_call_id = tool_calls[0].id\n",
    "    tool_function_name = tool_calls[0].function.name\n",
    "    tool_query_string = json.loads(tool_calls[0].function.arguments)\n",
    "    \n",
    "    # Step 3: Call the function and retrieve results. Append the results to the messages list.      \n",
    "    if tool_function_name == 'get_weather':\n",
    "        location = tool_query_string[\"location\"]\n",
    "        \n",
    "        try:\n",
    "            unit = tool_query_string['unit']\n",
    "        except:\n",
    "            unit = 'celcius'\n",
    "        \n",
    "        tool_result = execute_weather_tool(location=location,unit=unit)\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\":\"tool\", \n",
    "            \"tool_call_id\":tool_call_id, \n",
    "            \"name\": tool_function_name, \n",
    "            \"content\":tool_result\n",
    "        })\n",
    "        \n",
    "        # Step 4: Invoke the chat completions API with the function response appended to the messages list\n",
    "        # Note that messages with role 'tool' must be a response to a preceding message with 'tool_calls'\n",
    "        \n",
    "        chat_response = chat_completion_request(\n",
    "        messages)\n",
    "        \n",
    "        assistant_message = chat_response.choices[0].message\n",
    "        messages.append(assistant_message)\n",
    "\n",
    "        print(chat_response.choices[0].message.content)\n",
    "    \n",
    "    else: \n",
    "        print(f\"Error: function {tool_function_name} does not exist\")\n",
    "else: \n",
    "    # Model did not identify a function to call, result can be returned to the user \n",
    "    print(assistant_message.content) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d76bdbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"}\n",
      "{'role': 'user', 'content': \"What's the weather like today\"}\n",
      "{'role': 'user', 'content': \"I'm in liverpool.\"}\n",
      "ChatCompletionMessage(content='{\\n  \"location\": \"Liverpool\",\\n  \"unit\": \"celsius\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='chatcmpl-tool-3bc82308b9b2442594ba4c90ed08ed86', function=Function(arguments='{\\n  \"location\": \"Liverpool\",\\n  \"unit\": \"celsius\"\\n}', name='get_weather'), type='function')], reasoning_content='The user asks: \"What\\'s the weather like today\" and then says \"I\\'m in Liverpool.\" So we need to get the current weather for Liverpool. The user wants the weather. We can call the function get_weather with location \"Liverpool\". The user didn\\'t specify unit; we can default to Celsius or Fahrenheit? The function signature: location: string, unit?: \"celsius\" | \"fahrenheit\". The user didn\\'t specify unit, so we can either omit unit or ask. Usually we can default to Celsius (since UK uses Celsius). But we could ask the user if they\\'d like Celsius or Fahrenheit. However the user just asked \"What\\'s the weather like today\" and gave location. It\\'s safe to assume they want the current weather in their location. We can call the function with location \"Liverpool\". The function will return weather data. Then we can respond with a natural language answer.\\n\\nWe need to call the function.')\n",
      "{'role': 'tool', 'tool_call_id': 'chatcmpl-tool-3bc82308b9b2442594ba4c90ed08ed86', 'name': 'get_weather', 'content': '{\"location\": \"Liverpool\", \"weather\": \"Rainy, 12 degrees, Wind: High\", \"unit\": \"celsius\"}'}\n",
      "ChatCompletionMessage(content='In Liverpool today it’s rainy with a temperature around\\u202f12\\u202f°C and fairly strong winds. Let me know if you’d like a longer‑term forecast or any other details!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content='The user asked: \"What\\'s the weather like today\" and then \"I\\'m in Liverpool.\" So we need to provide the weather. The function get_weather returned a commentary with location, weather, unit. The function returned: {\"location\": \"Liverpool\", \"weather\": \"Rainy, 12 degrees, Wind: High\", \"unit\": \"celsius\"}.\\n\\nWe need to respond to the user with a friendly answer. Possibly also ask if they need more details. The system says not to assume values; but we have the function output. So we can answer: \"In Liverpool today it\\'s rainy, about 12°C, with strong winds.\" Possibly add suggestions. Also ask if they need forecast. Provide a concise answer.\\n\\nThus final answer: \"It\\'s rainy, about 12°C, with high winds.\" Possibly mention that it\\'s typical for Liverpool. Also ask if they need more details.')\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    \n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f09147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\n",
      "\u001b[0m\n",
      "\u001b[32muser: What's the weather like today\n",
      "\u001b[0m\n",
      "\u001b[32muser: I'm in liverpool.\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {\n",
      "  \"location\": \"Liverpool\",\n",
      "  \"unit\": \"celsius\"\n",
      "}\n",
      "\u001b[0m\n",
      "\u001b[36mtool (get_weather): {\"location\": \"Liverpool\", \"weather\": \"Rainy, 12 degrees, Wind: High\", \"unit\": \"celsius\"}\n",
      "\u001b[0m\n",
      "\u001b[34massistant: In Liverpool today it’s rainy with a temperature around 12 °C and fairly strong winds. Let me know if you’d like a longer‑term forecast or any other details!\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADM_JURIX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
